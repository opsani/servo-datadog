#!/usr/bin/env python3
import json
import os
import sys
import time

import yaml
from datadog import initialize
from datadog import api as dog

from measure import Measure, ST_FAILED

DESC="Datadog measure driver for Opsani Optune"
VERSION="1.0.0"
HAS_CANCEL=True
PROGRESS_INTERVAL=30

DFLT_WARMUP     = 0
DFLT_DURATION   = 120
DFLT_TIME_AGGR  = 'avg'
DFLT_SPACE_AGGR = 'avg'
AGGR_OPERATORS  = ('avg', 'max', 'min', 'sum', 'raw')
API_KEY_FPATH   = os.getenv('OPTUNE_DATADOG_API_KEY_PATH', '/etc/optune-datadog-auth/api_key')
APP_KEY_FPATH   = os.getenv('OPTUNE_DATADOG_APP_KEY_PATH', '/etc/optune-datadog-auth/app_key')
CONFIG_FPATH    = os.getenv('CONFIG_FPATH', './config.yaml')


def inst_id(metric, metric_name, group_name):
    """get a suitable instance ID from a datadog series record.
    The 'scope' value is taken and post-processed to make it shorter if it turns out to be coming from a k8s cluster"""

    #
    scope = metric.get("scope")
    assert scope, 'Metric "{}" has to be grouped by some property, so we can define ' \
                  'it\'s multi-instance result ids'.format(metric_name)

    # try to interpret as tag:value,tag:value, ...
    # e.g.: kube_deployment:c1,kube_namespace:lk
    tags = dict([tag.split(':') for tag in scope.split(',')])

    assert group_name in tags, 'Cannot find group {} in response on metric "{}"'.format(group_name, metric_name)

    return tags.get(group_name)


class Datadog(Measure):

    @staticmethod
    def get_config(path=CONFIG_FPATH):
        try:
            config = yaml.load(open(path))['datadog']
            assert config and config.get('metrics'), 'No metrics has been provided at path "datadog.metrics" ' \
                                                     'in file located at {}'.format(path)
            return config
        except yaml.YAMLError as e:
            e.__cause__ = 'Error parsing config file located at {}: {}'.format(path, e.__cause__)
            raise
        except KeyError:
            raise KeyError('No `datadog` configuration has been provided in config file located '
                           'at {}'.format(path))

    # overwrites super
    def describe(self):
        # get dict of metrics active in the last 24 hours
        self.init_datadog()
        config = self.get_config()
        metrics = {}
        for name, metric in config['metrics'].items():
            metrics[name] = {'unit': metric.get('unit', '')}
        return metrics

    # overwrites super
    def handle_cancel(self, signal, frame):
        err = 'Exiting due to signal: {}'.format(signal)
        self.print_measure_error(err, ST_FAILED)

        sys.exit(3)

    # overwrites super
    def measure(self):
        config = self.get_config()
        # parse and valcheck control configuration
        assert 'control' in self.input_data, 'Input data missing control configuration'
        control  = self.input_data['control']
        warmup   = int(control.get('warmup', DFLT_WARMUP))
        duration = int(control.get('duration', DFLT_DURATION))
        assert warmup >= 0 and duration >= 0, \
            'Both warmup {} and duration {} must be non-negative'.format(warmup, duration)

        self.init_datadog()

        for metric_name, metric in config['metrics'].items():
            group_name = metric['use_as_instance_id']
            assert group_name, 'Property "use_as_instance_id" for metric "{}" has to be set. ' \
                               'It tells the driver what scope parameter to use when defining ' \
                               'instance id for particular metric.'.format(metric_name)
            query = metric['query'].replace(' ', '')

            # query datadog:  verify query is valid
            qval = self.query_datadog_metric(query, duration, metric_name, group_name)
            self.debug('Initial value for query {}:  {}'.format(query, qval))

        # sleep
        self.t_sleep = warmup + duration
        self.debug('Sleeping for {:d} seconds ({:d} warmup + {:d} duration)'.format(self.t_sleep, warmup, duration))
        time.sleep(self.t_sleep)

        metrics = {}
        for metric_name, metric in config['metrics'].items():
            group_name = metric['use_as_instance_id']
            assert group_name, 'Property "use_as_instance_id" for metric "{}" has to be set. ' \
                               'It tells the driver what scope parameter to use when defining ' \
                               'instance id for particular metric.'.format(metric_name)
            query = metric['query'].replace(' ', '')

            # query datadog:  measure
            qval = self.query_datadog_metric(query, duration, metric_name, group_name)

            # construct result
            metrics.update({
                metric_name: {
                    'values': qval,
                    'annotation': query,
                }
            })

        annotations = {}

        return metrics, annotations

    # overwrites super:  update progress before printing it
    def print_progress(
            self,
            message=None,
            msg_index=None,
            stage=None,
            stageprogress=None):

        # update progress based on how much time has elapsed
        t_taken = time.time() - self.t_measure_start
        self.progress = int(min(100.0, 100.0*((t_taken)/self.t_sleep)))
        super().print_progress(message, msg_index, stage, stageprogress)

    # helper:  initialize datadog api module
    def init_datadog(self):

        # as required:  read api_key and app_key from files (e.g., from k8s
        # secret volume mounted files)
        if not hasattr(self, 'datadog_api_key'):
            assert os.path.isfile(API_KEY_FPATH), \
                'Datadog api_key file {} does not exist'.format(API_KEY_FPATH)
            with open(API_KEY_FPATH, 'r') as f:
                self.datadog_api_key = f.read().rstrip()
        if not hasattr(self, 'datadog_app_key'):
            assert os.path.isfile(APP_KEY_FPATH), \
                'Datadog app_key file {} does not exist'.format(APP_KEY_FPATH)
            with open(APP_KEY_FPATH, 'r') as f:
                self.datadog_app_key = f.read().rstrip()

        # initialize datadog api module
        options = {
            'api_key': self.datadog_api_key,
            'app_key': self.datadog_app_key
        }
        try:
            initialize(**options)
        except Exception as e:
            raise Exception('Failed to initialize Datadog API module. Error: {}'.format(str(e)))

    # helper:  query datadog metrics over last duration seconds and return
    # value computed from aggregating in time and space
    def query_datadog_metric(self, query, duration, metric_name, group_name):
        # query datadog metrics
        try:
            now = int(time.time())
            data = dog.Metric.query(start=now - duration, end=now, query=query)
        except Exception as e:
            raise Exception('Failed to query Datadog for metric {}. Error: {}'.format(query, str(e)))

        # verify query status and response type
        q_status = data.get('status')
        assert q_status == 'ok', \
            'Datadog query {} returned with status {} errors {}'.format(query, q_status, data.get('errors'))
        q_res_type = data.get('res_type')
        assert q_res_type == 'time_series', \
            'Datadog query {} res_type is not time_series but {}'.format(query, q_res_type)

        d = []
        for s in data.get('series', []):
            d.append({'id': inst_id(s, metric_name, group_name), 'data': [[int(p[0]), p[1]] for p in s['pointlist']]})

        return d


if __name__ == '__main__':
    dd = Datadog(VERSION, DESC, HAS_CANCEL, PROGRESS_INTERVAL)
    dd.run()
